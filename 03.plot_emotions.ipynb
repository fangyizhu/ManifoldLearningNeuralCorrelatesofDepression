{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T00:25:05.764470Z",
     "start_time": "2025-08-21T00:25:05.716968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "gc.collect()"
   ],
   "id": "6f6a9b2ab8f98d23",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from utils import *\n",
    "from torch import load, nn\n",
    "import torch.nn.functional as f\n",
    "from transformers import AutoTokenizer\n",
    "from pandas import DataFrame\n",
    "import plotly.express as px\n",
    "from collections import OrderedDict\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "id": "7d19f487645e3ed0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "MODEL = \"google/gemma-2-2b\"\n",
    "EMBEDDING_FILE = \"embeddings_google_gemma-2-2b.pth\"\n",
    "DEVICE = \"cuda:0\" # run on my gpu"
   ],
   "id": "bdc23479725dc48d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T00:25:28.475567Z",
     "start_time": "2025-08-21T00:25:17.069072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load pretrained tokenizer from model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# load local embedding file\n",
    "saved_embeddings = load(EMBEDDING_FILE)\n",
    "if 'weight' not in saved_embeddings:\n",
    "    raise KeyError(\"The saved embeddings file does not contain 'weight' key.\")\n",
    "embeddings_tensor = saved_embeddings['weight']\n",
    "\n",
    "# Create an embedding only model object\n",
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        return self.embedding(input_ids)\n",
    "\n",
    "# Create an empty LLM model that has the same shape with extracted embeddings\n",
    "emb_model = EmbeddingModel(*embeddings_tensor.size()).to(DEVICE)\n",
    "\n",
    "# Give the LLM model the weight of extracted embeddings\n",
    "emb_model.embedding.weight.data = embeddings_tensor\n",
    "emb_model.eval()"
   ],
   "id": "434bd3831ac0dee7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingModel(\n",
       "  (embedding): Embedding(256000, 2304)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T00:25:28.653437Z",
     "start_time": "2025-08-21T00:25:28.644414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(tokenizer(\"depressed\", return_tensors='pt').input_ids)\n",
    "print(tokenizer(\"elated\", return_tensors='pt').input_ids)\n",
    "print(tokenizer.decode(3243))\n",
    "print(tokenizer.decode(3734))\n",
    "print(tokenizer.decode(521))\n",
    "print(tokenizer.decode(840))"
   ],
   "id": "af1ced401ea3b00e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2, 3243, 3734]])\n",
      "tensor([[  2, 521, 840]])\n",
      "dep\n",
      "ressed\n",
      "el\n",
      "ated\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T00:27:10.550734Z",
     "start_time": "2025-08-21T00:27:10.541625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emotions = [\"happy\", \"calm\", \"content\", \"sad\", \"anxious\", \"lonely\", \"bitter\", \"angry\", \"scared\", \"fearful\"]\n",
    "print({emo: tokenizer(emo, return_tensors='pt').input_ids for emo in emotions})\n",
    "\n",
    "for emo in emotions:\n",
    "    \n",
    "\n",
    "# squeeze tensor dim, strip <bos>\n",
    "emo_tokens = OrderedDict({emo: tokenizer(emo, return_tensors='pt').input_ids.squeeze()[1] for emo in emotions})\n",
    "print(emo_tokens)"
   ],
   "id": "36eda89b64376ec8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'happy': tensor([[    2, 11896]]), 'calm': tensor([[     2, 116051]]), 'content': tensor([[   2, 3312]]), 'sad': tensor([[    2, 37968]]), 'anxious': tensor([[    2,   481, 24192]]), 'lonely': tensor([[     2, 151738]]), 'bitter': tensor([[     2, 158930]]), 'angry': tensor([[    2, 70709]]), 'scared': tensor([[     2, 221959]]), 'fearful': tensor([[    2, 71339,  1329]]), 'el': tensor([[  2, 521]]), 'ated': tensor([[  2, 840]]), 'dep': tensor([[   2, 3243]]), 'ressed': tensor([[   2, 3734]])}\n",
      "OrderedDict({'happy': tensor(11896), 'calm': tensor(116051), 'content': tensor(3312), 'sad': tensor(37968), 'anxious': tensor(481), 'lonely': tensor(151738), 'bitter': tensor(158930), 'angry': tensor(70709), 'scared': tensor(221959), 'fearful': tensor(71339), 'el': tensor(521), 'ated': tensor(840), 'dep': tensor(3243), 'ressed': tensor(3734)})\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "emo_embs = OrderedDict({k: emb_model(v) for k, v in emo_tokens.items()})",
   "id": "70dc5a5723ee1154"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T22:50:09.442037Z",
     "start_time": "2025-08-15T22:50:09.437330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sanity check\n",
    "print(f.cosine_similarity(emo_embs['happy'], emo_embs['happy'], dim=0))"
   ],
   "id": "cc531c2b16ab2f48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000, grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T22:50:09.464552Z",
     "start_time": "2025-08-15T22:50:09.461323Z"
    }
   },
   "cell_type": "code",
   "source": "emo_pairs = list(combinations(emo_embs, r=2))",
   "id": "b18011450952e58a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# put all the numbers in pandas df then plot\n",
    "\n",
    "\n",
    "df = DataFrame(index=emotions+[\"depressed-avg\", \"elated-avg\"], columns=emotions+[\"depressed-avg\", \"elated-avg\"])\n",
    "for p in combinations(emotions, r=2):\n",
    "    df[p[0]][p[1]]= cos_dist(emo_embs[p[0]], emo_embs[p[1]])\n",
    "\n",
    "# handle averaging for depressed and elated\n",
    "for emo in emotions:\n",
    "    df[emo]['depressed-avg'] = (cos_dist(emo_embs[emo], emo_embs['dep']) + cos_dist(emo_embs[emo], emo_embs['ressed'])) / 2\n",
    "    df[emo]['elated-avg'] = (cos_dist(emo_embs[emo], emo_embs['el']) + cos_dist(emo_embs[emo], emo_embs['ated'])) / 2\n",
    "df['depressed-avg']['elated-avg'] = (cos_dist(emo_embs['dep'], emo_embs['el']) + cos_dist(emo_embs['ressed'], emo_embs['ated'])) / 2\n",
    "\n",
    "fig1 = px.imshow(df, title=\"Cosine Distance between Emotions\", labels=dict(color=\"Cosine Distance\"), text_auto=True, aspect=\"auto\", color_continuous_scale='RdBu')\n",
    "print(\"Note: dep-ressed and el-ated got split into two embeddings in the LLM, we are taking the average cosine distance.\")\n",
    "fig1.show()"
   ],
   "id": "59a9e8b38ffe2315"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# put all the numbers in pandas df then plot\n",
    "\n",
    "\n",
    "df = DataFrame(index=emotions+[\"depressed-avg\", \"elated-avg\"], columns=emotions+[\"depressed-avg\", \"elated-avg\"])\n",
    "for p in combinations(emotions, r=2):\n",
    "    df[p[0]][p[1]]= euc(emo_embs[p[0]], emo_embs[p[1]])\n",
    "\n",
    "# handle averaging for depressed and elated\n",
    "for emo in emotions:\n",
    "    df[emo]['depressed-avg'] = (euc(emo_embs[emo], emo_embs['dep']) + euc(emo_embs[emo], emo_embs['ressed'])) / 2\n",
    "    df[emo]['elated-avg'] = (euc(emo_embs[emo], emo_embs['el']) + euc(emo_embs[emo], emo_embs['ated'])) / 2\n",
    "df['depressed-avg']['elated-avg'] = (euc(emo_embs['dep'], emo_embs['el']) + euc(emo_embs['ressed'], emo_embs['ated'])) / 2\n",
    "\n",
    "fig2 = px.imshow(df, title=\"Euclidean Distance between Emotions\", labels=dict(color=\"Euclidean Distance\"), text_auto=True, aspect=\"auto\", color_continuous_scale='RdBu')\n",
    "print(print(\"Note: dep-ressed and el-ated got split into two embeddings in the LLM, we are taking the euclidean distance.\"))\n",
    "fig2.show()"
   ],
   "id": "cad710bbf7bf22f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "figures_to_html([fig1, fig2], filename=\"results/03.emotion_distances.html\")",
   "id": "16e3a3c1d6e8162f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
