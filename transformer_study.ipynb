{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-08T01:55:23.923626Z",
     "start_time": "2025-08-08T01:55:23.919839Z"
    }
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "MODEL = \"openai/gpt-oss-20b\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T01:51:50.842816Z",
     "start_time": "2025-08-08T01:51:49.816704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# A study of Tokenizers: https://learn.deeplearning.ai/courses/how-transformer-llms-work/lesson/e34gz/tokenizers\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "emotions = [\"happy\", \"sad\", \"anxious\", \"calm\", \"depressed\", \"elated\"]\n",
    "emotion_tokens = [tokenizer(emo).input_ids for emo in emotions]\n",
    "print(emotion_tokens)"
   ],
   "id": "6fad7857fb55e977",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51917], [121007], [270, 87, 1595], [5842, 76], [613, 26974], [296, 780]]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T01:51:50.906057Z",
     "start_time": "2025-08-08T01:51:50.899415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DSM_DEPRESSION = \"Depression is a mood disorder that causes a persistent feeling of sadness and loss of interest.\"\n",
    "print(DSM_DEPRESSION)\n",
    "print(tokenizer(DSM_DEPRESSION))\n",
    "print(\"Depression\")\n",
    "print(tokenizer(\"Depression\"))\n",
    "print(\"depression\")\n",
    "print(tokenizer(\"depression\"))\n",
    "print(\"Depressed\")\n",
    "print(tokenizer(\"Depressed\"))\n",
    "print(\"Depress\")\n",
    "print(tokenizer(\"Depress\"))\n",
    "print(\"Dep\")\n",
    "print(tokenizer(\"Dep\"))\n",
    "print(\"pression\")\n",
    "print(tokenizer(\"pression\"))\n",
    "print(\"dep\")\n",
    "print(tokenizer(\"dep\"))\n",
    "print(\"Depp\")\n",
    "print(tokenizer(\"Depp\"))\n",
    "print(\"press\")\n",
    "print(tokenizer(\"press\"))\n",
    "print(\"pressed\")\n",
    "print(tokenizer(\"pressed\"))\n",
    "print(\"pression\")\n",
    "print(tokenizer(\"pression\"))"
   ],
   "id": "179e28818cc5e152",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depression is a mood disorder that causes a persistent feeling of sadness and loss of interest.\n",
      "{'input_ids': [8000, 15210, 382, 261, 25199, 31145, 484, 16431, 261, 43952, 10656, 328, 79740, 326, 6266, 328, 3425, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Depression\n",
      "{'input_ids': [8000, 15210], 'attention_mask': [1, 1]}\n",
      "depression\n",
      "{'input_ids': [613, 4521], 'attention_mask': [1, 1]}\n",
      "Depressed\n",
      "{'input_ids': [8000, 23406], 'attention_mask': [1, 1]}\n",
      "Depress\n",
      "{'input_ids': [8000, 799], 'attention_mask': [1, 1]}\n",
      "Dep\n",
      "{'input_ids': [8000], 'attention_mask': [1]}\n",
      "pression\n",
      "{'input_ids': [4521], 'attention_mask': [1]}\n",
      "dep\n",
      "{'input_ids': [27480], 'attention_mask': [1]}\n",
      "Depp\n",
      "{'input_ids': [1923, 654], 'attention_mask': [1, 1]}\n",
      "press\n",
      "{'input_ids': [2020], 'attention_mask': [1]}\n",
      "pressed\n",
      "{'input_ids': [26974], 'attention_mask': [1]}\n",
      "pression\n",
      "{'input_ids': [4521], 'attention_mask': [1]}\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T01:51:50.926597Z",
     "start_time": "2025-08-08T01:51:50.922736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "depression_tokens = [8000, 15210, 613, 4521, 799, 23406]\n",
    "print(depression_tokens)\n",
    "print([tokenizer.decode(tok) for tok in depression_tokens])\n",
    "# decode: token id -> text, encode: text -> token id, code ~= token"
   ],
   "id": "d29781f8f8e290f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8000, 15210, 613, 4521, 799, 23406]\n",
      "['Dep', 'ression', 'de', 'pression', 'ress', 'ressed']\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Observations: \"Depression\" and \"depression\" have different tokens. And they are both split into two tokens each.",
   "id": "7c07f349f1fdb9a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T01:51:50.952407Z",
     "start_time": "2025-08-08T01:51:50.948152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# A list of colors in RGB for representing the tokens\n",
    "colors = [\n",
    "    '102;194;165', '252;141;98', '141;160;203',\n",
    "    '231;138;195', '166;216;84', '255;217;47'\n",
    "]\n",
    "\n",
    "def show_tokens(sentence: str, tokenizer_name: str):\n",
    "    \"\"\" Show the tokens each separated by a different color \"\"\"\n",
    "\n",
    "    # Load the tokenizer and tokenize the input\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    token_ids = tokenizer(sentence).input_ids\n",
    "\n",
    "    # Extract vocabulary length\n",
    "    print(f\"Vocab length: {len(tokenizer)}\")\n",
    "\n",
    "    # Print a colored list of tokens\n",
    "    for idx, t in enumerate(token_ids):\n",
    "        print(\n",
    "            f'\\x1b[0;30;48;2;{colors[idx % len(colors)]}m' +\n",
    "            tokenizer.decode(t) +\n",
    "            '\\x1b[0m',\n",
    "            end=' '\n",
    "        )"
   ],
   "id": "dd62806e920ec09e",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T01:51:54.182655Z",
     "start_time": "2025-08-08T01:51:50.974440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "show_tokens(DSM_DEPRESSION, \"openai/gpt-oss-20b\")\n",
    "print()\n",
    "show_tokens(DSM_DEPRESSION, \"openai/gpt-oss-120b\")"
   ],
   "id": "c6fbf95aab797f36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab length: 200019\n",
      "\u001B[0;30;48;2;102;194;165mDep\u001B[0m \u001B[0;30;48;2;252;141;98mression\u001B[0m \u001B[0;30;48;2;141;160;203m is\u001B[0m \u001B[0;30;48;2;231;138;195m a\u001B[0m \u001B[0;30;48;2;166;216;84m mood\u001B[0m \u001B[0;30;48;2;255;217;47m disorder\u001B[0m \u001B[0;30;48;2;102;194;165m that\u001B[0m \u001B[0;30;48;2;252;141;98m causes\u001B[0m \u001B[0;30;48;2;141;160;203m a\u001B[0m \u001B[0;30;48;2;231;138;195m persistent\u001B[0m \u001B[0;30;48;2;166;216;84m feeling\u001B[0m \u001B[0;30;48;2;255;217;47m of\u001B[0m \u001B[0;30;48;2;102;194;165m sadness\u001B[0m \u001B[0;30;48;2;252;141;98m and\u001B[0m \u001B[0;30;48;2;141;160;203m loss\u001B[0m \u001B[0;30;48;2;231;138;195m of\u001B[0m \u001B[0;30;48;2;166;216;84m interest\u001B[0m \u001B[0;30;48;2;255;217;47m.\u001B[0m \n",
      "Vocab length: 200019\n",
      "\u001B[0;30;48;2;102;194;165mDep\u001B[0m \u001B[0;30;48;2;252;141;98mression\u001B[0m \u001B[0;30;48;2;141;160;203m is\u001B[0m \u001B[0;30;48;2;231;138;195m a\u001B[0m \u001B[0;30;48;2;166;216;84m mood\u001B[0m \u001B[0;30;48;2;255;217;47m disorder\u001B[0m \u001B[0;30;48;2;102;194;165m that\u001B[0m \u001B[0;30;48;2;252;141;98m causes\u001B[0m \u001B[0;30;48;2;141;160;203m a\u001B[0m \u001B[0;30;48;2;231;138;195m persistent\u001B[0m \u001B[0;30;48;2;166;216;84m feeling\u001B[0m \u001B[0;30;48;2;255;217;47m of\u001B[0m \u001B[0;30;48;2;102;194;165m sadness\u001B[0m \u001B[0;30;48;2;252;141;98m and\u001B[0m \u001B[0;30;48;2;141;160;203m loss\u001B[0m \u001B[0;30;48;2;231;138;195m of\u001B[0m \u001B[0;30;48;2;166;216;84m interest\u001B[0m \u001B[0;30;48;2;255;217;47m.\u001B[0m "
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Observation: gpt-oss models share the same tokenizer between two model sizes.",
   "id": "9c794a871c90872f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-08T01:55:47.986549Z",
     "start_time": "2025-08-08T01:55:47.307882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# A study of Transformers: https://learn.deeplearning.ai/courses/how-transformer-llms-work/lesson/m3nid/model-example\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    device_map=\"cpu\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ],
   "id": "2753c38690212215",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# A study of Transformers: https://learn.deeplearning.ai/courses/how-transformer-llms-work/lesson/m3nid/model-example\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m model = \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mMODEL\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcpu\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mauto\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\Users\\rhodo\\OneDrive\\Documents\\GitHub\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:600\u001B[39m, in \u001B[36m_BaseAutoModelClass.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[39m\n\u001B[32m    598\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m model_class.config_class == config.sub_configs.get(\u001B[33m\"\u001B[39m\u001B[33mtext_config\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    599\u001B[39m         config = config.get_text_config()\n\u001B[32m--> \u001B[39m\u001B[32m600\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    601\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    602\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    603\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    604\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig.\u001B[34m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    605\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m, \u001B[39m\u001B[33m'\u001B[39m.join(c.\u001B[34m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m._model_mapping)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    606\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\Users\\rhodo\\OneDrive\\Documents\\GitHub\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:316\u001B[39m, in \u001B[36mrestore_default_torch_dtype.<locals>._wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    314\u001B[39m old_dtype = torch.get_default_dtype()\n\u001B[32m    315\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m316\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    317\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    318\u001B[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\Users\\rhodo\\OneDrive\\Documents\\GitHub\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4784\u001B[39m, in \u001B[36mPreTrainedModel.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[39m\n\u001B[32m   4782\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mDeepSpeed Zero-3 is not compatible with passing a `device_map`.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   4783\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_accelerate_available():\n\u001B[32m-> \u001B[39m\u001B[32m4784\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   4785\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mUsing a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4786\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mrequires `accelerate`. You can install it with `pip install accelerate`\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   4787\u001B[39m         )\n\u001B[32m   4789\u001B[39m \u001B[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001B[39;00m\n\u001B[32m   4790\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m load_in_4bit \u001B[38;5;129;01mor\u001B[39;00m load_in_8bit:\n",
      "\u001B[31mValueError\u001B[39m: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "52339fcf3a36b37a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
