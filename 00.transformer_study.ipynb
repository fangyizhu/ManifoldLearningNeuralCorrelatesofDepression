{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-18T19:54:45.060140Z",
     "start_time": "2025-08-18T19:54:44.989131Z"
    }
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T19:54:45.075973Z",
     "start_time": "2025-08-18T19:54:45.066907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL = \"google/gemma-2b\"\n",
    "DEVICE = \"cuda:0\" # run on my gpu"
   ],
   "id": "22a605644289a2b2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T19:54:46.858379Z",
     "start_time": "2025-08-18T19:54:45.086326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# A study of Tokenizers: https://learn.deeplearning.ai/courses/how-transformer-llms-work/lesson/e34gz/tokenizers\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "emotions = [\"happy\", \"sad\", \"anxious\", \"calm\", \"depressed\", \"elated\"]\n",
    "emotion_tokens = [tokenizer(emo).input_ids for emo in emotions]\n",
    "print(emotion_tokens)"
   ],
   "id": "6fad7857fb55e977",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 11896], [2, 37968], [2, 481, 24192], [2, 116051], [2, 3243, 3734], [2, 521, 840]]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T19:54:47.065115Z",
     "start_time": "2025-08-18T19:54:47.030779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DSM_DEPRESSION = \"Depression is a mood disorder that causes a persistent feeling of sadness and loss of interest.\"\n",
    "print(DSM_DEPRESSION)\n",
    "print(tokenizer(DSM_DEPRESSION))\n",
    "print(\"Depression\")\n",
    "print(tokenizer(\"Depression\"))\n",
    "print(\"depression\")\n",
    "print(tokenizer(\"depression\"))\n",
    "print(\"Depressed\")\n",
    "print(tokenizer(\"Depressed\"))\n",
    "print(\"Depress\")\n",
    "print(tokenizer(\"Depress\"))\n",
    "print(\"Dep\")\n",
    "print(tokenizer(\"Dep\"))\n",
    "print(\"pression\")\n",
    "print(tokenizer(\"pression\"))\n",
    "print(\"dep\")\n",
    "print(tokenizer(\"dep\"))\n",
    "print(\"Depp\")\n",
    "print(tokenizer(\"Depp\"))\n",
    "print(\"press\")\n",
    "print(tokenizer(\"press\"))\n",
    "print(\"pressed\")\n",
    "print(tokenizer(\"pressed\"))\n",
    "print(\"pression\")\n",
    "print(tokenizer(\"pression\"))"
   ],
   "id": "179e28818cc5e152",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depression is a mood disorder that causes a persistent feeling of sadness and loss of interest.\n",
      "{'input_ids': [2, 116465, 603, 476, 18068, 24283, 674, 10792, 476, 36727, 7965, 576, 51863, 578, 4783, 576, 3273, 235265], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Depression\n",
      "{'input_ids': [2, 116465], 'attention_mask': [1, 1]}\n",
      "depression\n",
      "{'input_ids': [2, 161067], 'attention_mask': [1, 1]}\n",
      "Depressed\n",
      "{'input_ids': [2, 5789, 3734], 'attention_mask': [1, 1, 1]}\n",
      "Depress\n",
      "{'input_ids': [2, 5789, 1054], 'attention_mask': [1, 1, 1]}\n",
      "Dep\n",
      "{'input_ids': [2, 5789], 'attention_mask': [1, 1]}\n",
      "pression\n",
      "{'input_ids': [2, 206753], 'attention_mask': [1, 1]}\n",
      "dep\n",
      "{'input_ids': [2, 3243], 'attention_mask': [1, 1]}\n",
      "Depp\n",
      "{'input_ids': [2, 1680, 658], 'attention_mask': [1, 1, 1]}\n",
      "press\n",
      "{'input_ids': [2, 11355], 'attention_mask': [1, 1]}\n",
      "pressed\n",
      "{'input_ids': [2, 49716], 'attention_mask': [1, 1]}\n",
      "pression\n",
      "{'input_ids': [2, 206753], 'attention_mask': [1, 1]}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T19:54:47.102820Z",
     "start_time": "2025-08-18T19:54:47.098497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test_tokens = [8000, 15210, 613, 4521, 799, 23406]\n",
    "# print(test_tokens)\n",
    "# print([tokenizer.decode(tok) for tok in test_tokens])\n",
    "# decode: token id -> text, encode: text -> token id, code ~= token"
   ],
   "id": "d29781f8f8e290f",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note: In gpt-oss \"Depression\" and \"depression\" have different tokens. And they are both split into two tokens each.",
   "id": "7c07f349f1fdb9a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T19:54:47.130893Z",
     "start_time": "2025-08-18T19:54:47.118373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# A list of colors in RGB for representing the tokens\n",
    "colors = [\n",
    "    '102;194;165', '252;141;98', '141;160;203',\n",
    "    '231;138;195', '166;216;84', '255;217;47'\n",
    "]\n",
    "\n",
    "def show_tokens(sentence: str, tokenizer_name: str):\n",
    "    \"\"\" Show the tokens each separated by a different color \"\"\"\n",
    "\n",
    "    # Load the tokenizer and tokenize the input\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    token_ids = tokenizer(sentence).input_ids\n",
    "\n",
    "    # Extract vocabulary length\n",
    "    print(f\"Vocab length: {len(tokenizer)}\")\n",
    "\n",
    "    # Print a colored list of tokens\n",
    "    for idx, t in enumerate(token_ids):\n",
    "        print(\n",
    "            f'\\x1b[0;30;48;2;{colors[idx % len(colors)]}m' +\n",
    "            tokenizer.decode(t) +\n",
    "            '\\x1b[0m',\n",
    "            end=' '\n",
    "        )"
   ],
   "id": "dd62806e920ec09e",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T19:54:48.284690Z",
     "start_time": "2025-08-18T19:54:47.140808Z"
    }
   },
   "cell_type": "code",
   "source": "show_tokens(DSM_DEPRESSION, MODEL)",
   "id": "c6fbf95aab797f36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab length: 256000\n",
      "\u001B[0;30;48;2;102;194;165m<bos>\u001B[0m \u001B[0;30;48;2;252;141;98mDepression\u001B[0m \u001B[0;30;48;2;141;160;203m is\u001B[0m \u001B[0;30;48;2;231;138;195m a\u001B[0m \u001B[0;30;48;2;166;216;84m mood\u001B[0m \u001B[0;30;48;2;255;217;47m disorder\u001B[0m \u001B[0;30;48;2;102;194;165m that\u001B[0m \u001B[0;30;48;2;252;141;98m causes\u001B[0m \u001B[0;30;48;2;141;160;203m a\u001B[0m \u001B[0;30;48;2;231;138;195m persistent\u001B[0m \u001B[0;30;48;2;166;216;84m feeling\u001B[0m \u001B[0;30;48;2;255;217;47m of\u001B[0m \u001B[0;30;48;2;102;194;165m sadness\u001B[0m \u001B[0;30;48;2;252;141;98m and\u001B[0m \u001B[0;30;48;2;141;160;203m loss\u001B[0m \u001B[0;30;48;2;231;138;195m of\u001B[0m \u001B[0;30;48;2;166;216;84m interest\u001B[0m \u001B[0;30;48;2;255;217;47m.\u001B[0m "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Observation: gpt-oss models share the same tokenizer between two model sizes.",
   "id": "9c794a871c90872f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T19:55:31.551498Z",
     "start_time": "2025-08-18T19:54:48.366750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# A study of Transformers: https://learn.deeplearning.ai/courses/how-transformer-llms-work/lesson/m3nid/model-example\n",
    "torch.cuda.empty_cache()\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    device_map=\"cuda:0\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ],
   "id": "b52ccaab2842b32f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e8d4e8a09714525ac5b23d47b1d013e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T19:55:31.805564Z",
     "start_time": "2025-08-18T19:55:31.753215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False, # False means to not include the prompt text in the returned text\n",
    "    max_new_tokens=50,\n",
    "    do_sample=False, # no randomness in the generated text\n",
    ")"
   ],
   "id": "9273aa1a1a618900",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-18T19:55:31.811528Z"
    }
   },
   "cell_type": "code",
   "source": "print(generator(DSM_DEPRESSION)[0]['generated_text'])",
   "id": "3de01c77e389b877",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T19:18:25.611246Z",
     "start_time": "2025-08-14T19:18:25.605527Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "6f6215974dac1359",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaForCausalLM(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-17): 18 x GemmaDecoderLayer(\n",
       "        (self_attn): GemmaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
       "          (act_fn): GELUActivation()\n",
       "        )\n",
       "        (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): GemmaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T19:18:25.620545Z",
     "start_time": "2025-08-14T19:18:25.616671Z"
    }
   },
   "cell_type": "code",
   "source": "model.model.embed_tokens",
   "id": "b410525b8f98316d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(256000, 2048, padding_idx=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T19:18:25.641745Z",
     "start_time": "2025-08-14T19:18:25.636757Z"
    }
   },
   "cell_type": "code",
   "source": "model.model # printing the stack of transformer blocks without the LM head component",
   "id": "40afbabb0bb2ad03",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaModel(\n",
       "  (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
       "  (layers): ModuleList(\n",
       "    (0-17): 18 x GemmaDecoderLayer(\n",
       "      (self_attn): GemmaAttention(\n",
       "        (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "        (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "        (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (mlp): GemmaMLP(\n",
       "        (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "        (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "        (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
       "        (act_fn): GELUActivation()\n",
       "      )\n",
       "      (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "      (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "  (rotary_emb): GemmaRotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T19:18:25.662159Z",
     "start_time": "2025-08-14T19:18:25.658034Z"
    }
   },
   "cell_type": "code",
   "source": "model.model.layers[0]",
   "id": "e09996c2aaa4d72b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaDecoderLayer(\n",
       "  (self_attn): GemmaAttention(\n",
       "    (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "    (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "    (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "    (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "  )\n",
       "  (mlp): GemmaMLP(\n",
       "    (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "    (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "    (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
       "    (act_fn): GELUActivation()\n",
       "  )\n",
       "  (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "  (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T19:18:25.694050Z",
     "start_time": "2025-08-14T19:18:25.678087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(DSM_DEPRESSION)\n",
    "input_ids = tokenizer(DSM_DEPRESSION, return_tensors=\"pt\").input_ids.to(DEVICE) # pt probably means pytorch\n",
    "input_ids"
   ],
   "id": "4e0d024fb0465bde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depression is a mood disorder that causes a persistent feeling of sadness and loss of interest.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[     2, 116465,    603,    476,  18068,  24283,    674,  10792,    476,\n",
       "          36727,   7965,    576,  51863,    578,   4783,    576,   3273, 235265]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T19:18:25.783655Z",
     "start_time": "2025-08-14T19:18:25.727623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the output of the model before the lm_head\n",
    "model_output = model.model(input_ids)"
   ],
   "id": "351a2bf8bfac464c",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T19:18:25.836650Z",
     "start_time": "2025-08-14T19:18:25.832413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the shape the output the model before the lm_head\n",
    "model_output[0].shape"
   ],
   "id": "56f7b54b4efe6401",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18, 2048])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T19:18:26.317116Z",
     "start_time": "2025-08-14T19:18:26.312988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the output of the lm_head\n",
    "lm_head_output = model.lm_head(model_output[0])\n",
    "lm_head_output.shape"
   ],
   "id": "1607a3a3e4545ec8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18, 256000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T19:18:26.539183Z",
     "start_time": "2025-08-14T19:18:26.532682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_id = lm_head_output[0,-1].argmax(-1)\n",
    "token_id"
   ],
   "id": "b3d14aaf4e442c4c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1165, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T19:18:26.591912Z",
     "start_time": "2025-08-14T19:18:26.587090Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.decode(token_id)",
   "id": "70280dc79c1f045d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' It'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T19:18:26.635206Z",
     "start_time": "2025-08-14T19:18:26.633373Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "437e3c27a5562866",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
